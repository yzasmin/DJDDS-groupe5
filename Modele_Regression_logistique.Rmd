---
title: "data science grp 5"
output: html_document
date: "2024-11-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
current_directory <- getwd()

# Afficher le répertoire de travail
print(current_directory)
setwd("/Users/justinemanuel/Documents/GitHub/DJDDS-groupe5")
```

# Données

```{r}

# Charger les bibliothèques nécessaires
library(ggplot2)
library(readr)

# Charger les données depuis le fichier CSV avec un point-virgule comme délimiteur et un séparateur décimal
donnees <- read.csv2("DATA/farms_train.csv")
# Charger la bibliothèque nécessaire
library(tidyr)

# Lire le fichier CSV (en supposant que le séparateur entre les colonnes est une virgule)
donnees2 <- read.csv("DATA/farms_test.csv", sep = ",", header = TRUE, stringsAsFactors = FALSE)




# Afficher les premières lignes pour vérifier les données
head(donnees)
head(donnees2)

```

```{r}
library(caret)
set.seed(123)  # Pour rendre la partition reproductible

# Partitionner les données d'entraînement : 80% pour l'entraînement, 20% pour le test
partition <- createDataPartition(donnees$DIFF, p = 0.8, list = FALSE)

# Données d'entraînement (80%)
train_data <- donnees[partition, ]

# Données de test (20%)
test_data <- donnees[ -partition, ]

# Vérifier la taille des jeux de données
cat("Taille des données d'entraînement : ", nrow(train_data), "\n")
cat("Taille des données de test : ", nrow(test_data), "\n")

# Vérifier les premières lignes des jeux de données d'entraînement et de test
head(train_data)
head(test_data)
```
```{r}
train_data$DIFF <- factor(train_data$DIFF)
str(train_data$DIFF)
test_data$DIFF <- factor(test_data$DIFF)
str(test_data$DIFF)
# Vérifiez le type des variables explicatives
sapply(train_data[, c("R2", "R7", "R8", "R17", "R22", "R32")], class)
sapply(test_data[, c("R2", "R7", "R8", "R17", "R22", "R32")], class)
```

```{r}
# Vérifier la présence de valeurs manquantes dans le jeu de données
sum(is.na(train_data))
```

# Model de Régression

```{r}
# Charger les bibliothèques nécessaires
library(dplyr)   # Pour manipuler les données

# Créer un modèle de régression logistique sur les données d'entraînement
log_model <- glm(DIFF ~ R2 + R7 + R8 + R17 + R22 + R32, data = train_data, family = binomial)

# Résumé du modèle pour voir les coefficients
summary(log_model)

```



```{r}
# Faire des prédictions sur les données de test
# Utiliser le modèle logistique pour prédire la probabilité que DIFF = 1
predictions_prob <- predict(log_model, test_data, type = "response")

# Convertir les probabilités en classes binaires
predictions_class <- ifelse(predictions_prob > 0.5, 1, 0)

# Convertir les prédictions en facteur pour la comparaison avec la variable cible dans les données de test
predictions_class <- factor(predictions_class, levels = c(0, 1))

# Calculer la matrice de confusion pour évaluer la performance du modèle
library(caret)
conf_matrix <- confusionMatrix(predictions_class, test_data$DIFF)

# Afficher la matrice de confusion
print(conf_matrix)

# Extraire l'accuracy (précision globale) du modèle
accuracy <- conf_matrix$overall['Accuracy']
cat("Accuracy: ", accuracy, "\n")
```

```{r}
# Charger les bibliothèques nécessaires
library(pROC)
library(ROCR)

# 1. Courbe ROC et AUC
roc_curve <- roc(test_data$DIFF, predictions_prob)  # Calculer la courbe ROC
cat("AUC: ", auc(roc_curve), "\n")  # Afficher l'AUC

# Tracer la courbe ROC
roc_plot <- ggroc(roc_curve) +
  ggtitle("Courbe ROC") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Taux de faux positifs (FPR)", y = "Taux de vrais positifs (TPR)") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray")

print(roc_plot)
```

```{r}
# 2. Sensibilité et Spécificité
# Créer des objets de prédiction avec ROCR
pred_rocr <- prediction(predictions_prob, test_data$DIFF)

# Calculer les performances à différents seuils
perf <- performance(pred_rocr, measure = "tpr", x.measure = "fpr")  # Sensibilité (TPR) vs. Spécificité (1 - FPR)
sensitivity_specificity <- performance(pred_rocr, measure = "sens", x.measure = "spec")

# Tracer les courbes de sensibilité et spécificité
sens_spec_plot <- ggplot() +
  geom_line(aes(x = sensitivity_specificity@x.values[[1]], 
                y = sensitivity_specificity@y.values[[1]]), 
            color = "blue") +
  labs(title = "Courbe Sensibilité vs. Spécificité", 
       x = "Spécificité (1 - FPR)", y = "Sensibilité (TPR)") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(labels = scales::percent) +
  scale_y_continuous(labels = scales::percent)

print(sens_spec_plot)
```
# Prédiction sur les données test

```{r}
head(donnees2)
str(donnees2_separated)
donnees2_separated$R2 <- as.numeric(donnees2_separated$R2)
donnees2_separated$R7 <- as.numeric(donnees2_separated$R7)
donnees2_separated$R8 <- as.numeric(donnees2_separated$R8)
donnees2_separated$R17 <- as.numeric(donnees2_separated$R17)
donnees2_separated$R22 <- as.numeric(donnees2_separated$R22)
donnees2_separated$R32 <- as.numeric(donnees2_separated$R32)
str(donnees2_separated)
```


```{r}
# Prédictions sur les données2
predictions_prob <- predict(log_model, newdata = donnees2_separated, type = "response")

# Convertir les probabilités en classes binaires (si nécessaire)
predictions_class <- ifelse(predictions_prob > 0.5, 1, 0)

# Convertir les prédictions en facteur (0, 1)
predictions_class <- factor(predictions_class, levels = c(0, 1))

# Afficher les résultats
print(predictions_class)

```
```{r}
head(donnees2)
head(donnees)
```


```{r}
# Créer un dataframe avec les ID et les prédictions de classe (DIFF)
predictions_df <- data.frame(
  ID = seq_len(nrow(donnees2)),
  DIFF = predictions_class 
)

# Sauvegarder ce dataframe dans un fichier CSV
write.csv(predictions_df, "soumission.csv", row.names = FALSE)

# Afficher le message de confirmation
cat("Le fichier CSV avec les prédictions a été créé sous le nom 'soumission.csv'.")
```

```{r}
# Créer un dataframe des prédictions de classe
class_df <- data.frame(
  Classe = predictions_class
)

# Visualisation avec un barplot pour voir le nombre de prédictions dans chaque classe
ggplot(class_df, aes(x = factor(Classe), fill = factor(Classe))) +
  geom_bar() +
  ggtitle("Distribution des Prédictions de Classe") +
  xlab("Classe Prédite") +
  ylab("Nombre de Prédictions") +
  scale_fill_manual(values = c("steelblue", "coral")) +
  theme_minimal() +
  theme(legend.position = "none")
```



# Visualisation sur les données train

```{r}
# Graphique 1: DIFF vs R2
ggplot(donnees, aes(x = DIFF, y = R2)) +  
  geom_point() +  
  labs(title = "Graphique de dispersion : DIFF vs R2", x = "DIFF", y = "R2") +
  theme_minimal()

# Graphique 2: DIFF vs R7
ggplot(donnees, aes(x = DIFF, y = R7)) +  
  geom_point() +  
  labs(title = "Graphique de dispersion : DIFF vs R7", x = "DIFF", y = "R7") +
  theme_minimal()

# Graphique 3: DIFF vs R8
ggplot(donnees, aes(x = DIFF, y = R8)) +  
  geom_point() +  
  labs(title = "Graphique de dispersion : DIFF vs R8", x = "DIFF", y = "R8") +
  theme_minimal()

# Graphique 4: DIFF vs R17
ggplot(donnees, aes(x = DIFF, y = R17)) +  
  geom_point() +  
  labs(title = "Graphique de dispersion : DIFF vs R17", x = "DIFF", y = "R17") +
  theme_minimal()

# Graphique 5: DIFF vs R22
ggplot(donnees, aes(x = DIFF, y = R22)) +  
  geom_point() +  
  labs(title = "Graphique de dispersion : DIFF vs R22", x = "DIFF", y = "R22") +
  theme_minimal()

# Graphique 6: DIFF vs R32
ggplot(donnees, aes(x = DIFF, y = R32)) +  
  geom_point() +  
  labs(title = "Graphique de dispersion : DIFF vs R32", x = "DIFF", y = "R32") +
  theme_minimal()
```

```{r}

```


